{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01932a57-c8a0-414e-9048-f343c0fb08ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 16:35:11 WARN SQLConf: The SQL config 'spark.sql.execution.arrow.enabled' has been deprecated in Spark v3.0 and may be removed in the future. Use 'spark.sql.execution.arrow.pyspark.enabled' instead of it.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing completed.\n",
      "+--------------------+------+\n",
      "|           open_time|volume|\n",
      "+--------------------+------+\n",
      "|2020-08-11 06:00:...|  6115|\n",
      "|2020-08-11 06:15:...|  2813|\n",
      "|2020-08-11 06:30:...|  9207|\n",
      "|2020-08-11 06:45:...|  1895|\n",
      "|2020-08-11 07:00:...|  5723|\n",
      "|2020-08-11 07:15:...|  7339|\n",
      "|2020-08-11 07:30:...| 20720|\n",
      "|2020-08-11 07:45:...|  8286|\n",
      "|2020-08-11 08:00:...| 13904|\n",
      "|2020-08-11 08:15:...|  4970|\n",
      "+--------------------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%timeit\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark.rdd import RDD\n",
    "from pyspark.sql.dataframe import DataFrame as DataFrame\n",
    "from pandas.core.frame import DataFrame as PandasDataframe\n",
    "\n",
    "# Run the date count jobs tasks\n",
    "from transformations.solana import SparkJob\n",
    "\n",
    "LOG_FILENAME = 'solana.log'\n",
    "logging.basicConfig(filename=LOG_FILENAME, level=logging.INFO)\n",
    "\n",
    "\n",
    "job = SparkJob()\n",
    "df = job.solana_pivot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82cfb401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+---------------------+-----+----+------+------+\n",
      "|           open_time|current_date|current_date_formated|month|year|minute|volume|\n",
      "+--------------------+------------+---------------------+-----+----+------+------+\n",
      "|2020-08-11 06:00:...|  2022-04-26|           2022 04 26|    8|2020|     0|  6115|\n",
      "|2020-08-11 06:15:...|  2022-04-26|           2022 04 26|    8|2020|    15|  2813|\n",
      "|2020-08-11 06:30:...|  2022-04-26|           2022 04 26|    8|2020|    30|  9207|\n",
      "|2020-08-11 06:45:...|  2022-04-26|           2022 04 26|    8|2020|    45|  1895|\n",
      "|2020-08-11 07:00:...|  2022-04-26|           2022 04 26|    8|2020|     0|  5723|\n",
      "|2020-08-11 07:15:...|  2022-04-26|           2022 04 26|    8|2020|    15|  7339|\n",
      "|2020-08-11 07:30:...|  2022-04-26|           2022 04 26|    8|2020|    30| 20720|\n",
      "|2020-08-11 07:45:...|  2022-04-26|           2022 04 26|    8|2020|    45|  8286|\n",
      "|2020-08-11 08:00:...|  2022-04-26|           2022 04 26|    8|2020|     0| 13904|\n",
      "|2020-08-11 08:15:...|  2022-04-26|           2022 04 26|    8|2020|    15|  4970|\n",
      "+--------------------+------------+---------------------+-----+----+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.select(\n",
    "    'open_time', \n",
    "    current_date().alias('current_date') ,  \n",
    "    date_format(current_timestamp(),\"yyyy MM dd\").alias(\"current_date_formated\"),\n",
    "    month('open_time').alias('month'),\n",
    "    year('open_time').alias('year'),\n",
    "    minute('open_time').alias('minute'),\n",
    "    'volume',\n",
    "    )\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffe7f75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|minute|       1|       2|       3|       4|       5|       6|       7|       8|       9|      10|      11|      12|\n",
      "+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "|    45|72759699|61131529|43685972|56939322|59246741|48367201|24520142|51869187|75641544|37206056|34954910|28942546|\n",
      "|     0|77520818|65527873|47153244|62967852|68444012|53791560|27199974|55576471|81330684|45798614|38569070|33633018|\n",
      "|    30|74504056|63273295|44054054|57387350|58995975|47733935|25121176|53492405|78352750|39010925|35327033|29743231|\n",
      "|    15|74007151|61964958|43937033|56883349|62698409|49322669|25446075|53030447|79780201|40973773|36300445|30047677|\n",
      "+------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 07:31:31 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 1750466 ms exceeds timeout 120000 ms\n",
      "22/04/26 07:31:31 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"minute\") \\\n",
    "    .pivot(\"month\") \\\n",
    "    .sum('volume').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b937c77-1e4f-4854-b936-d9791fdeb836",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/26 04:46:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+----+----+---+-----+-------+----------+------------------+----------------+--------------+---------------+------+----------+\n",
      "|open_time                    |open|high|low|close|volume |close_time|quote_asset_volume|number_of_trades|tb_base_volume|tb_quote_volume|ignore|row_number|\n",
      "+-----------------------------+----+----+---+-----+-------+----------+------------------+----------------+--------------+---------------+------+----------+\n",
      "|2021-01-08 10:00:00.000000000|2   |3   |2  |3    |2248151|null      |6843551           |13377           |1357068       |4114713        |0     |1         |\n",
      "|2021-05-20 17:00:00.000000000|44  |53  |44 |48   |2201043|null      |107395538         |121890          |1205511       |58868213       |0     |2         |\n",
      "|2021-01-08 12:30:00.000000000|3   |3   |3  |3    |1744730|null      |6238414           |12269           |956660        |3418708        |0     |3         |\n",
      "|2021-01-07 10:15:00.000000000|2   |2   |2  |2    |1432337|null      |3158376           |11059           |663729        |1469763        |0     |4         |\n",
      "|2021-01-07 12:30:00.000000000|2   |2   |2  |2    |1332209|null      |3213102           |10744           |968013        |2337930        |0     |5         |\n",
      "|2020-09-09 14:45:00.000000000|3   |3   |3  |3    |1267905|null      |4600079           |7977            |626287        |2269559        |0     |6         |\n",
      "|2021-01-08 10:15:00.000000000|3   |3   |3  |3    |1251187|null      |3920896           |7352            |673622        |2114521        |0     |7         |\n",
      "|2021-09-07 15:00:00.000000000|152 |160 |128|146  |1245441|null      |182761364         |177208          |578064        |84932172       |0     |8         |\n",
      "|2021-01-07 00:30:00.000000000|2   |2   |2  |2    |1237486|null      |2855877           |7932            |746627        |1728016        |0     |9         |\n",
      "|2021-01-08 12:45:00.000000000|3   |3   |3  |3    |1198360|null      |4407754           |7208            |676408        |2493591        |0     |10        |\n",
      "|2021-05-17 17:00:00.000000000|51  |51  |46 |47   |1154937|null      |56386489          |65030           |473058        |22986742       |0     |11        |\n",
      "|2021-01-07 12:45:00.000000000|2   |2   |2  |2    |1130090|null      |2885898           |10513           |620576        |1586813        |0     |12        |\n",
      "|2021-01-08 09:45:00.000000000|2   |2   |2  |2    |1080713|null      |2908672           |6494            |587902        |1581881        |0     |13        |\n",
      "|2021-01-07 10:45:00.000000000|2   |2   |2  |2    |1067167|null      |2263924           |9138            |619479        |1316806        |0     |14        |\n",
      "|2021-01-07 12:00:00.000000000|2   |2   |2  |2    |1060464|null      |2390452           |8263            |679595        |1531283        |0     |15        |\n",
      "|2021-05-19 12:45:00.000000000|35  |41  |26 |35   |1001962|null      |33550383          |48357           |471740        |15909731       |0     |16        |\n",
      "|2021-01-08 11:00:00.000000000|2   |3   |2  |3    |942522 |null      |2927050           |6497            |520868        |1624535        |0     |17        |\n",
      "|2021-09-07 15:15:00.000000000|146 |164 |141|158  |938859 |null      |148345663         |165171          |465464        |73542078       |0     |18        |\n",
      "|2021-01-07 10:00:00.000000000|2   |2   |2  |2    |934722 |null      |1951760           |6497            |304658        |640222         |0     |19        |\n",
      "|2021-01-08 10:45:00.000000000|3   |3   |2  |2    |896426 |null      |2667354           |4825            |335828        |999976         |0     |20        |\n",
      "+-----------------------------+----+----+---+-----+-------+----------+------------------+----------------+--------------+---------------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# Creating a window.\n",
    "window = Window.partitionBy(\"high\").orderBy(df[\"volume\"].desc())\n",
    "\n",
    "df.withColumn(\"row_number\",row_number().over(window)) \\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7debb786",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'case1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/demo-spark-pipelines/notebooks/solana.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6b6176692f776f726b7370616365732f706572736f6e616c2f64656d6f2d737061726b2d706970656c696e6573/workspaces/demo-spark-pipelines/notebooks/solana.ipynb#ch0000002vscode-remote?line=0'>1</a>\u001b[0m df3 \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mselect(split(df\u001b[39m.\u001b[39;49mcase1,\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B2f55736572732f6b6176692f776f726b7370616365732f706572736f6e616c2f64656d6f2d737061726b2d706970656c696e6573/workspaces/demo-spark-pipelines/notebooks/solana.ipynb#ch0000002vscode-remote?line=1'>2</a>\u001b[0m df3\u001b[39m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1643\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1632'>1633</a>\u001b[0m \u001b[39m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1633'>1634</a>\u001b[0m \n\u001b[1;32m   <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1634'>1635</a>\u001b[0m \u001b[39m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1639'>1640</a>\u001b[0m \u001b[39m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1640'>1641</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1641'>1642</a>\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m-> <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1642'>1643</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1643'>1644</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n\u001b[1;32m   <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1644'>1645</a>\u001b[0m jc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jdf\u001b[39m.\u001b[39mapply(name)\n\u001b[1;32m   <a href='file:///root/.cache/pypoetry/virtualenvs/data-transformations-_a9Tn7A7-py3.9/lib/python3.9/site-packages/pyspark/sql/dataframe.py?line=1645'>1646</a>\u001b[0m \u001b[39mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'case1'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/04/25 22:33:30 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 666749 ms exceeds timeout 120000 ms\n",
      "22/04/25 22:33:30 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "df3 = df.select(split(df.case1,\"\"))\n",
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92d0e88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
